{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN\n",
    "This Program is using cats breed dataset with around 50 labels.\n",
    "There are two source that being used in this program. The good one from robots, and the worse is from keagle dataset.\n",
    "This prgram is using transferlearning with ResNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Libraries\n",
    "- ### OS\n",
    "Interacting with file in user acccess\n",
    "- ### Shutil\n",
    "Interacting with file in admin access\n",
    "- ### re\n",
    "regex library for working with string\n",
    "- ### random\n",
    "using randomize thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Datasets\n",
    "importing dataset from local folder and also preparing stuff for data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path\n",
    "there are 3 option of dataset to use in this program. From Kaggle, Robots, and the merged one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_source = r\"../Dataset/\"\n",
    "dataset_all = r\"Merged Dataset All/\"\n",
    "dataset_kaggle = r\"Merged Dataset Kaggle/\"\n",
    "dataset_robot = r\"Robots Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset review\n",
    "Chekking how many dataset classes and how many image per classes. dataset infomation is stored in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_review(dataset_type):\n",
    "    \"\"\"Checking what directory exist in datataset directory\n",
    "\n",
    "    Args:\n",
    "        dataset_type (string): root path for choosen dataset\n",
    "\n",
    "    Returns:\n",
    "        dictionary: store dictionary name as key and sum of image in it\n",
    "    \"\"\"\n",
    "    dataset_path = os.path.join(path_source, dataset_type)\n",
    "    folders = {}\n",
    "    \n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folders[folder] = len(os.listdir(os.path.join(dataset_path, folder)))\n",
    "    \n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 classes with 2403 images in total\n",
      "\n",
      "class Abyssinian have 203 images\n",
      "class Bengal have 200 images\n",
      "class Birman have 200 images\n",
      "class Bombay have 200 images\n",
      "class British Shorthair have 200 images\n",
      "class Egyptian Mau have 200 images\n",
      "class Maine Coon have 200 images\n",
      "class Persian have 200 images\n",
      "class Ragdoll have 200 images\n",
      "class Russian Blue have 200 images\n",
      "class Siamese have 200 images\n",
      "class Sphynx have 200 images\n"
     ]
    }
   ],
   "source": [
    "datasetDict = dataset_review(dataset_robot)\n",
    "\n",
    "temp = 0\n",
    "for key in datasetDict:\n",
    "    temp += datasetDict[key]\n",
    "\n",
    "print(f\"There are {len(datasetDict)} classes with {temp} images in total\", end=\"\\n\\n\")\n",
    "for key, value in datasetDict.items():\n",
    "    print(f\"class {key} have {value} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Preparation\n",
    "Creating training and validation directory for storing dataset when split data process is on progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(rooth_path, folders):\n",
    "    \"\"\"Create the directory for later be the place to store a suitable dataset\n",
    "\n",
    "    Args:\n",
    "        rooth_path (string): the root path where directory will be created\n",
    "        folders (dict): dictionary that store label name and the summary of images inside it\n",
    "    \"\"\"\n",
    "    if os.path.isdir(os.path.join(rooth_path, \"training\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'training')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"training\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"training/{folder}\"))\n",
    "    \n",
    "    if os.path.isdir(os.path.join(rooth_path, \"validation\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'validation')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"validation\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"validation/{folder}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(os.path.join(path_source, f\"{dataset_robot}../robot_used\"), datasetDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "The split_dataset function is splitting dataset into 2 dataset. Training dataset and Validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(sourcePath, trainPath, valPath, splitSize):\n",
    "    \"\"\"split dataset image into training and valdation \n",
    "\n",
    "    Args:\n",
    "        sourcePath (string): source path where unprocessed dataset is stored\n",
    "        trainPath (string): path that will be the train set stored\n",
    "        valPath (string): path that will be the validation set stored\n",
    "        splitSize (int): will be the percentage of training set size\n",
    "    \"\"\"\n",
    "    # list of file names\n",
    "    files = []\n",
    "    \n",
    "    # add all the file name in the list\n",
    "    for file_name in os.listdir(sourcePath):\n",
    "        if os.path.getsize(os.path.join(sourcePath, file_name)):\n",
    "            files.append(file_name)\n",
    "        else:\n",
    "            print(f\"{file_name} is ignored\")\n",
    "    \n",
    "    # define the split point and shuffle the file\n",
    "    split_point = int(splitSize * len(files))\n",
    "    shuffled_file = random.sample(files, len(files))\n",
    "    \n",
    "    # define the train and validation val list\n",
    "    trainFile = shuffled_file[:split_point]\n",
    "    valFile = shuffled_file[split_point:]\n",
    "    \n",
    "    # copying the file into the correct directory\n",
    "    for file_train in trainFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_train),\n",
    "                        os.path.join(trainPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_train).lower()))\n",
    "    for file_val in valFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_val),\n",
    "                        os.path.join(valPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_val).lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring global variabel\n",
    "This variabel is storing destination and source path for the used dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_destinationPath = os.path.join(path_source, f\"{dataset_robot}../robot_used\")\n",
    "dataset_sourcePath = os.path.join(path_source, dataset_robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset Proccess\n",
    "This cell is calling split_dataset function for each folder(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder Abyssinian image copy succes.\n",
      "folder American Bobtail copy is failed ===========\n",
      "folder American Curl copy is failed ===========\n",
      "folder American Shorthair copy is failed ===========\n",
      "folder Applehead Siamese copy is failed ===========\n",
      "folder Balinese copy is failed ===========\n",
      "folder Bengal image copy succes.\n",
      "folder Birman image copy succes.\n",
      "folder Bombay image copy succes.\n",
      "folder British Shorthair image copy succes.\n",
      "folder Burmese copy is failed ===========\n",
      "folder Calico copy is failed ===========\n",
      "folder Chartreux copy is failed ===========\n",
      "folder Cornish Rex copy is failed ===========\n",
      "folder Devon Rex copy is failed ===========\n",
      "folder Dilute Calico copy is failed ===========\n",
      "folder Dilute Tortoiseshell copy is failed ===========\n",
      "folder Domestic Long Hair copy is failed ===========\n",
      "folder Domestic Medium Hair copy is failed ===========\n",
      "folder Domestic Short Hair copy is failed ===========\n",
      "folder Egyptian Mau image copy succes.\n",
      "folder Exotic Shorthair copy is failed ===========\n",
      "folder Extra-Toes Cat - Hemingway Polydactyl copy is failed ===========\n",
      "folder Havana copy is failed ===========\n",
      "folder Himalayan copy is failed ===========\n",
      "folder Japanese Bobtail copy is failed ===========\n",
      "folder Korat copy is failed ===========\n",
      "folder Maine Coon image copy succes.\n",
      "folder Manx copy is failed ===========\n",
      "folder Munchkin copy is failed ===========\n",
      "folder Nebelung copy is failed ===========\n",
      "folder Norwegian Forest Cat copy is failed ===========\n",
      "folder Ocicat copy is failed ===========\n",
      "folder Oriental Long Hair - oriental long hair copy is failed ===========\n",
      "folder Oriental Short Hair copy is failed ===========\n",
      "folder Oriental Tabby copy is failed ===========\n",
      "folder Persian image copy succes.\n",
      "folder Pixiebob copy is failed ===========\n",
      "folder Ragamuffin copy is failed ===========\n",
      "folder Ragdoll image copy succes.\n",
      "folder Russian Blue image copy succes.\n",
      "folder Scottish Fold copy is failed ===========\n",
      "folder Selkirk Rex copy is failed ===========\n",
      "folder Siamese image copy succes.\n",
      "folder Siberian copy is failed ===========\n",
      "folder Silver copy is failed ===========\n",
      "folder Snowshoe copy is failed ===========\n",
      "folder Sphynx image copy succes.\n",
      "folder Sphynx - Hairless Cat copy is failed ===========\n",
      "folder Tabby copy is failed ===========\n",
      "folder Tiger copy is failed ===========\n",
      "folder Tonkinese copy is failed ===========\n",
      "folder Torbie copy is failed ===========\n",
      "folder Tortoiseshell copy is failed ===========\n",
      "folder Turkish Angora copy is failed ===========\n",
      "folder Turkish Van copy is failed ===========\n",
      "folder Tuxedo copy is failed ===========\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(os.path.join(path_source, dataset_all)):\n",
    "    train_dir = os.path.join(dataset_destinationPath, f\"training/{folder}\")\n",
    "    val_dir = os.path.join(dataset_destinationPath, f\"validation/{folder}\")\n",
    "    \n",
    "    try:\n",
    "        split_dataset(os.path.join(dataset_sourcePath, folder), train_dir, val_dir, 0.7)\n",
    "        print(f\"folder {folder} image copy succes.\")\n",
    "    except:\n",
    "        print(f\"folder {folder} copy is failed\", \"===========\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a698132df0d61d2c04481168cd60695d48e6b3ce384607f3b1f9e0e40157999"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
