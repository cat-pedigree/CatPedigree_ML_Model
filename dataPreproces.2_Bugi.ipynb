{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN - ResNet\n",
    "This Program is using cats breed dataset with around 50 labels.\n",
    "There are two source that being used in this program. The good one from robots, and the worse is from keagle dataset.\n",
    "This prgram is using transferlearning with ResNet.\n",
    "## Outline\n",
    "- Import libraries\n",
    "- Import dataset\n",
    "- Split dataset\n",
    "- Data Augmentation\n",
    "- Model structuring\n",
    "- Model Training\n",
    "- Visualisasi Hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Datasets\n",
    "importing dataset from local folder and also preparing stuff for data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path\n",
    "there are 3 option of dataset to use in this program. From Kaggle, Robots, and the merged one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_source = r\"../Dataset/\"\n",
    "dataset_all = r\"Merged Dataset All/\"\n",
    "dataset_kaggle = r\"Merged Dataset Kaggle/\"\n",
    "dataset_robot = r\"Robots Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset review\n",
    "Chekking how many dataset classes and how many image per classes. dataset infomation is stored in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_review(dataset_type):\n",
    "    \"\"\"Checking what directory exist in datataset directory\n",
    "\n",
    "    Args:\n",
    "        dataset_type (string): root path for choosen dataset\n",
    "\n",
    "    Returns:\n",
    "        dictionary: store dictionary name as key and sum of image in it\n",
    "    \"\"\"\n",
    "    dataset_path = os.path.join(path_source, dataset_type)\n",
    "    folders = {}\n",
    "    \n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folders[folder] = len(os.listdir(os.path.join(dataset_path, folder)))\n",
    "    \n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 classes with 2403 images in total\n",
      "\n",
      "class Abyssinian have 203 images\n",
      "class Bengal have 200 images\n",
      "class Birman have 200 images\n",
      "class Bombay have 200 images\n",
      "class British Shorthair have 200 images\n",
      "class Egyptian Mau have 200 images\n",
      "class Maine Coon have 200 images\n",
      "class Persian have 200 images\n",
      "class Ragdoll have 200 images\n",
      "class Russian Blue have 200 images\n",
      "class Siamese have 200 images\n",
      "class Sphynx have 200 images\n"
     ]
    }
   ],
   "source": [
    "datasetDict = dataset_review(dataset_robot)\n",
    "\n",
    "temp = 0\n",
    "for key in datasetDict:\n",
    "    temp += datasetDict[key]\n",
    "\n",
    "print(f\"There are {len(datasetDict)} classes with {temp} images in total\", end=\"\\n\\n\")\n",
    "for key, value in datasetDict.items():\n",
    "    print(f\"class {key} have {value} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Preparation\n",
    "Creating training, testing, and/or validation directory for storing dataset split later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(rooth_path, folders):\n",
    "    if os.path.isdir(os.path.join(rooth_path, \"training\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'training')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"training\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"training/{folder}\"))\n",
    "    \n",
    "    if os.path.isdir(os.path.join(rooth_path, \"testing\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'testing')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"testing\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"testing/{folder}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(os.path.join(path_source, f\"{dataset_robot}../robot_used\"), datasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(sourcePath, trainPath, testPath, splitSize):\n",
    "    files = []\n",
    "    \n",
    "    for file_name in os.listdir(sourcePath):\n",
    "        if os.path.getsize(os.path.join(sourcePath, file_name)):\n",
    "            files.append(file_name)\n",
    "        else:\n",
    "            print(f\"{file_name} is ignored\")\n",
    "    \n",
    "    split_point = int(splitSize * len(files))\n",
    "    shuffled_file = random.sample(files, len(files))\n",
    "    \n",
    "    trainFile = shuffled_file[:split_point]\n",
    "    testFile = shuffled_file[split_point:]\n",
    "    \n",
    "    for file_train in trainFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_train),\n",
    "                        os.path.join(trainPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_train).lower()))\n",
    "    for file_test in testFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_test),\n",
    "                        os.path.join(testPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_test).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_destinationPath = os.path.join(path_source, f\"{dataset_robot}../robot_used\")\n",
    "dataset_sourcePath = os.path.join(path_source, dataset_robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder Abyssinian image copy succes.\n",
      "folder American Bobtail copy is failed ===========\n",
      "folder American Curl copy is failed ===========\n",
      "folder American Shorthair copy is failed ===========\n",
      "folder Applehead Siamese copy is failed ===========\n",
      "folder Balinese copy is failed ===========\n",
      "folder Bengal image copy succes.\n",
      "folder Birman image copy succes.\n",
      "folder Bombay image copy succes.\n",
      "folder British Shorthair image copy succes.\n",
      "folder Burmese copy is failed ===========\n",
      "folder Calico copy is failed ===========\n",
      "folder Chartreux copy is failed ===========\n",
      "folder Cornish Rex copy is failed ===========\n",
      "folder Devon Rex copy is failed ===========\n",
      "folder Dilute Calico copy is failed ===========\n",
      "folder Dilute Tortoiseshell copy is failed ===========\n",
      "folder Domestic Long Hair copy is failed ===========\n",
      "folder Domestic Medium Hair copy is failed ===========\n",
      "folder Domestic Short Hair copy is failed ===========\n",
      "folder Egyptian Mau image copy succes.\n",
      "folder Exotic Shorthair copy is failed ===========\n",
      "folder Extra-Toes Cat - Hemingway Polydactyl copy is failed ===========\n",
      "folder Havana copy is failed ===========\n",
      "folder Himalayan copy is failed ===========\n",
      "folder Japanese Bobtail copy is failed ===========\n",
      "folder Korat copy is failed ===========\n",
      "folder Maine Coon image copy succes.\n",
      "folder Manx copy is failed ===========\n",
      "folder Munchkin copy is failed ===========\n",
      "folder Nebelung copy is failed ===========\n",
      "folder Norwegian Forest Cat copy is failed ===========\n",
      "folder Ocicat copy is failed ===========\n",
      "folder Oriental Long Hair - oriental long hair copy is failed ===========\n",
      "folder Oriental Short Hair copy is failed ===========\n",
      "folder Oriental Tabby copy is failed ===========\n",
      "folder Persian image copy succes.\n",
      "folder Pixiebob copy is failed ===========\n",
      "folder Ragamuffin copy is failed ===========\n",
      "folder Ragdoll image copy succes.\n",
      "folder Russian Blue image copy succes.\n",
      "folder Scottish Fold copy is failed ===========\n",
      "folder Selkirk Rex copy is failed ===========\n",
      "folder Siamese image copy succes.\n",
      "folder Siberian copy is failed ===========\n",
      "folder Silver copy is failed ===========\n",
      "folder Snowshoe copy is failed ===========\n",
      "folder Sphynx image copy succes.\n",
      "folder Sphynx - Hairless Cat copy is failed ===========\n",
      "folder Tabby copy is failed ===========\n",
      "folder Tiger copy is failed ===========\n",
      "folder Tonkinese copy is failed ===========\n",
      "folder Torbie copy is failed ===========\n",
      "folder Tortoiseshell copy is failed ===========\n",
      "folder Turkish Angora copy is failed ===========\n",
      "folder Turkish Van copy is failed ===========\n",
      "folder Tuxedo copy is failed ===========\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(os.path.join(path_source, dataset_all)):\n",
    "    train_dir = os.path.join(dataset_destinationPath, f\"training/{folder}\")\n",
    "    test_dir = os.path.join(dataset_destinationPath, f\"testing/{folder}\")\n",
    "    \n",
    "    try:\n",
    "        split_dataset(os.path.join(dataset_sourcePath, folder), train_dir, test_dir, 0.7)\n",
    "        print(f\"folder {folder} image copy succes.\")\n",
    "    except:\n",
    "        print(f\"folder {folder} copy is failed\", \"===========\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a698132df0d61d2c04481168cd60695d48e6b3ce384607f3b1f9e0e40157999"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
