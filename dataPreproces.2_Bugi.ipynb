{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CNN - ResNet\n",
    "This Program is using cats breed dataset with around 50 labels.\n",
    "There are two source that being used in this program. The good one from robots, and the worse is from keagle dataset.\n",
    "This prgram is using transferlearning with ResNet.\n",
    "## Outline\n",
    "- Import libraries\n",
    "- Import dataset\n",
    "- Split dataset\n",
    "- Data Augmentation\n",
    "- Model structuring\n",
    "- Model Training\n",
    "- Visualisasi Hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import Datasets\n",
    "importing dataset from local folder and also preparing stuff for data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define path\n",
    "there are 3 option of dataset to use in this program. From Kaggle, Robots, and the merged one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_source = r\"../Dataset/\"\n",
    "dataset_all = r\"Merged Dataset All/\"\n",
    "dataset_kaggle = r\"Merged Dataset Kaggle/\"\n",
    "dataset_robot = r\"Robots Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset review\n",
    "Chekking how many dataset classes and how many image per classes. dataset infomation is stored in dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_review(dataset_type):\n",
    "    \"\"\"Checking what directory exist in datataset directory\n",
    "\n",
    "    Args:\n",
    "        dataset_type (string): root path for choosen dataset\n",
    "\n",
    "    Returns:\n",
    "        dictionary: store dictionary name as key and sum of image in it\n",
    "    \"\"\"\n",
    "    dataset_path = os.path.join(path_source, dataset_type)\n",
    "    folders = {}\n",
    "    \n",
    "    for folder in os.listdir(dataset_path):\n",
    "        folders[folder] = len(os.listdir(os.path.join(dataset_path, folder)))\n",
    "    \n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57 classes with 124380 images in total\n",
      "\n",
      "class Abyssinian have 428 images\n",
      "class American Bobtail have 919 images\n",
      "class American Curl have 139 images\n",
      "class American Shorthair have 4822 images\n",
      "class Applehead Siamese have 130 images\n",
      "class Balinese have 248 images\n",
      "class Bengal have 2544 images\n",
      "class Birman have 420 images\n",
      "class Bombay have 1919 images\n",
      "class British Shorthair have 753 images\n",
      "class Burmese have 335 images\n",
      "class Calico have 3345 images\n",
      "class Chartreux have 81 images\n",
      "class Cornish Rex have 159 images\n",
      "class Devon Rex have 112 images\n",
      "class Dilute Calico have 3121 images\n",
      "class Dilute Tortoiseshell have 3015 images\n",
      "class Domestic Long Hair have 4382 images\n",
      "class Domestic Medium Hair have 5323 images\n",
      "class Domestic Short Hair have 52105 images\n",
      "class Egyptian Mau have 500 images\n",
      "class Exotic Shorthair have 465 images\n",
      "class Extra-Toes Cat - Hemingway Polydactyl have 1154 images\n",
      "class Havana have 166 images\n",
      "class Himalayan have 1264 images\n",
      "class Japanese Bobtail have 125 images\n",
      "class Korat have 67 images\n",
      "class Maine Coon have 1578 images\n",
      "class Manx have 1991 images\n",
      "class Munchkin have 181 images\n",
      "class Nebelung have 144 images\n",
      "class Norwegian Forest Cat have 569 images\n",
      "class Ocicat have 117 images\n",
      "class Oriental Long Hair - oriental long hair have 37 images\n",
      "class Oriental Short Hair have 482 images\n",
      "class Oriental Tabby have 98 images\n",
      "class Persian have 4162 images\n",
      "class Pixiebob have 103 images\n",
      "class Ragamuffin have 116 images\n",
      "class Ragdoll have 2806 images\n",
      "class Russian Blue have 2048 images\n",
      "class Scottish Fold have 301 images\n",
      "class Selkirk Rex have 77 images\n",
      "class Siamese have 2296 images\n",
      "class Siberian have 156 images\n",
      "class Silver have 84 images\n",
      "class Snowshoe have 1597 images\n",
      "class Sphynx have 200 images\n",
      "class Sphynx - Hairless Cat have 209 images\n",
      "class Tabby have 2866 images\n",
      "class Tiger have 2209 images\n",
      "class Tonkinese have 250 images\n",
      "class Torbie have 3309 images\n",
      "class Tortoiseshell have 3788 images\n",
      "class Turkish Angora have 648 images\n",
      "class Turkish Van have 807 images\n",
      "class Tuxedo have 3110 images\n"
     ]
    }
   ],
   "source": [
    "datasetDict = dataset_review(dataset_all)\n",
    "\n",
    "temp = 0\n",
    "for key in datasetDict:\n",
    "    temp += datasetDict[key]\n",
    "\n",
    "print(f\"There are {len(datasetDict)} classes with {temp} images in total\", end=\"\\n\\n\")\n",
    "for key, value in datasetDict.items():\n",
    "    print(f\"class {key} have {value} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Preparation\n",
    "Creating training, testing, and/or validation directory for storing dataset split later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(rooth_path, folders):\n",
    "    if os.path.isdir(os.path.join(rooth_path, \"training\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'training')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"training\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"training/{folder}\"))\n",
    "    \n",
    "    if os.path.isdir(os.path.join(rooth_path, \"testing\")):\n",
    "        print(f\"this path {os.path.join(rooth_path, 'testing')} already made\")\n",
    "    else:\n",
    "        os.makedirs(os.path.join(rooth_path, \"testing\"))\n",
    "        for folder in folders.keys():\n",
    "            os.makedirs(os.path.join(rooth_path, f\"testing/{folder}\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this path ../Dataset/Used\\training already made\n",
      "this path ../Dataset/Used\\testing already made\n"
     ]
    }
   ],
   "source": [
    "create_dir(os.path.join(path_source, \"Used\"), datasetDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(sourcePath, trainPath, testPath, splitSize):\n",
    "    files = []\n",
    "    \n",
    "    for file_name in os.listdir(sourcePath):\n",
    "        if os.path.getsize(os.path.join(sourcePath, file_name)):\n",
    "            files.append(file_name)\n",
    "        else:\n",
    "            print(f\"{file_name} is ignored\")\n",
    "    \n",
    "    split_point = int(splitSize * len(files))\n",
    "    shuffled_file = random.sample(files, len(files))\n",
    "    \n",
    "    trainFile = shuffled_file[:split_point]\n",
    "    testFile = shuffled_file[split_point:]\n",
    "    \n",
    "    for file_train in trainFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_train),\n",
    "                        os.path.join(trainPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_train).lower()))\n",
    "    for file_test in testFile:\n",
    "        shutil.copyfile(os.path.join(sourcePath, file_test),\n",
    "                        os.path.join(testPath, re.sub(r\"([\\s/-]+)\", r\"_\", file_test).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder Abyssinian image copy succes.\n",
      "folder American Bobtail image copy succes.\n",
      "folder American Curl image copy succes.\n",
      "folder American Shorthair image copy succes.\n",
      "folder Applehead Siamese image copy succes.\n",
      "folder Balinese image copy succes.\n",
      "folder Bengal image copy succes.\n",
      "folder Birman image copy succes.\n",
      "folder Bombay image copy succes.\n",
      "folder British Shorthair image copy succes.\n",
      "folder Burmese image copy succes.\n",
      "folder Calico image copy succes.\n",
      "folder Chartreux image copy succes.\n",
      "folder Cornish Rex image copy succes.\n",
      "folder Devon Rex image copy succes.\n",
      "folder Dilute Calico image copy succes.\n",
      "folder Dilute Tortoiseshell image copy succes.\n",
      "folder Domestic Long Hair image copy succes.\n",
      "folder Domestic Medium Hair image copy succes.\n",
      "folder Domestic Short Hair image copy succes.\n",
      "folder Egyptian Mau image copy succes.\n",
      "folder Exotic Shorthair image copy succes.\n",
      "folder Extra-Toes Cat - Hemingway Polydactyl image copy succes.\n",
      "folder Havana image copy succes.\n",
      "folder Himalayan image copy succes.\n",
      "folder Japanese Bobtail image copy succes.\n",
      "folder Korat image copy succes.\n",
      "folder Maine Coon image copy succes.\n",
      "folder Manx image copy succes.\n",
      "folder Munchkin image copy succes.\n",
      "folder Nebelung image copy succes.\n",
      "folder Norwegian Forest Cat image copy succes.\n",
      "folder Ocicat image copy succes.\n",
      "folder Oriental Long Hair - oriental long hair image copy succes.\n",
      "folder Oriental Short Hair image copy succes.\n",
      "folder Oriental Tabby image copy succes.\n",
      "folder Persian image copy succes.\n",
      "folder Pixiebob image copy succes.\n",
      "folder Ragamuffin image copy succes.\n",
      "folder Ragdoll image copy succes.\n",
      "folder Russian Blue image copy succes.\n",
      "folder Scottish Fold image copy succes.\n",
      "folder Selkirk Rex image copy succes.\n",
      "folder Siamese image copy succes.\n",
      "folder Siberian image copy succes.\n",
      "folder Silver image copy succes.\n",
      "folder Snowshoe image copy succes.\n",
      "folder Sphynx image copy succes.\n",
      "folder Sphynx - Hairless Cat image copy succes.\n",
      "folder Tabby image copy succes.\n",
      "folder Tiger image copy succes.\n",
      "folder Tonkinese image copy succes.\n",
      "folder Torbie image copy succes.\n",
      "folder Tortoiseshell image copy succes.\n",
      "folder Turkish Angora image copy succes.\n",
      "folder Turkish Van image copy succes.\n",
      "folder Tuxedo image copy succes.\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(os.path.join(path_source, dataset_all)):\n",
    "    train_dir = os.path.join(f\"{path_source}/Used\", f\"training/{folder}\")\n",
    "    test_dir = os.path.join(f\"{path_source}/Used\", f\"testing/{folder}\")\n",
    "    \n",
    "    try:\n",
    "        split_dataset(os.path.join(f\"{path_source}/{dataset_all}\", folder), train_dir, test_dir, 0.9)\n",
    "        print(f\"folder {folder} image copy succes.\")\n",
    "    except:\n",
    "        print(f\"folder {folder} copy is failed\", \"===========\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6a698132df0d61d2c04481168cd60695d48e6b3ce384607f3b1f9e0e40157999"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
